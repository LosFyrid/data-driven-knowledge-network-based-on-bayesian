# Aetherium: 一个用于自主科学发现的框架

![状态: Alpha](https://img.shields.io/badge/status-alpha-orange.svg)
![Python: 3.10+](https://img.shields.io/badge/python-3.10%2B-blue.svg)
![许可证: MIT](https://img.shields.io/badge/license-MIT-lightgrey.svg)

> **核心愿景:** 创造一个“数字科学家”AI。它融合了概率推理与符号知识，不仅能对科学定律进行建模，还能理解这些定律的适用边界，并自主地发现新的科学假设。

---

## 1. 核心哲学

当前的AI方法难以统一三种关键类型的信息：

1.  **概率知识:** 从大型语言模型（LLM）训练海量文本中获得的、高层次的、广义的但模糊的理解。
2.  **符号知识:** 人类推导出的、精确的、“白盒”的公式和定律（例如 $F=ma$）。
3.  **数值数据:** 来自真实世界实验和模拟的、连续的、通常充满噪声的“次符号”数据。

**Aetherium** 是一个旨在弥合这一鸿沟的认知架构。它的运行方式不是简单地拟合数据，而是为其自身的知识建立一个**元认知模型 (meta-cognitive model)**。它的主要目标不仅仅是*使用*一条定律，而是去理解**这条定律在何时（when）适用**，以及**为什么（why）它会在其边界处失效**。

## 2. 核心架构：双循环系统

Aetherium的“大脑”是一个动态的双循环系统，它将“如何运作”（机制）与“何时适用”（情境）分离开来。

### `RuleClass`：符号化心脏

* `RuleClass` 是一个Python对象，代表一条科学定律或假设（例如 `NewtonianGravityRule`）。
* 它在设计上是**概率化**的。它的 `predict()` 方法不返回单个值，而是返回一个**概率分布**（例如 `stats.norm(mean, sigma)`）。
* 它包含需要被学习的**内部参数**（例如引力常数 $G$）。

### 循环一：内循环（“机械师”）

* **任务：** 回答“这条定律**如何**运作？”
* **机制：** 通过概率编程（例如 `PyMC`）进行贝叶斯更新（BU）。
* **过程：**
    1.  给定一个 `RuleClass` 和来自**单一情境**的**一批**实验数据，内循环会为该定律的*内部参数*找到最合理的**后验分布**。
    2.  然后，它计算一个关键指标：**模型证据 (model evidence)** 或 **似然得分 (likelihood score)**。这个单一的数字代表了这条定律在经过最佳调校后，对该特定情境下数据的“解释力”。

#### 内循环建模的三种模式

`RuleClass` 的具体实现方式取决于我们对规律拥有多少先验知识。这三种模式定义了内循环的灵活性和任务：

| 模式 | **白盒 (White-Box)** | **灰盒 (Gray-Box)** | **黑盒 (Black-Box)** |
| :--- | :--- | :--- | :--- |
| **定义** | 我们**明确知道**规律的**数学公式**（例如 $F=kx$）。 | 我们**不知道**确切公式，但知道某些变量的**定性属性**（如单调性、平滑性）。 | 我们对公式和属性**一无所知**。 |
| **内循环任务** | **参数估计**。使用弱先验（non-informative priors）让数据决定公式参数（如 $k$）。 | **约束下的函数拟合**。将已知的定性属性（如“$a$递增则$y$递增”）作为约束，来拟合一个灵活的函数。 | **无约束的函数拟合**。使用一个通用的非参数模型来逼近未知的函数 $y=f(a, b, ...)$。 |
| **首选实现** | 贝叶斯回归（例如 `pm.Normal('k', ...)`） | **广义可加模型 (GAMs)**。假设 $y = f_a(a) + f_b(b) + ...$，并使用P-样条为 $f_a$ 施加单调性约束。 | **标准高斯过程 (GP)**。使用RBF等通用核函数来建模一个完全未知的 $f$。 |
| **可解释性** | **高**（公式已知） | **中**（公式形式是灵活的，但约束和可加性本身是可解释的） | **低**（模型即数据，没有简洁公式） |
| **数据需求** | 中 | 中（约束有助于减少对数据的依赖） | 高 |
| **未来思路** | - | 约束高斯过程 (Constrained GP, CGP) 可以在不假设可加性的情况下施加属性约束，但计算更复杂。 | 贝叶斯神经网络 (BNN) |

Aetherium框架的美妙之处在于，外循环**不关心**内循环是白盒、灰盒还是黑盒。它只需要内循环返回一个总结性的似然得分，这种模块化设计提供了极大的灵活性。

### 循环二：外循环（“战略家”/ 元认知）

* **任务：** 回答“这条定律**何时**适用？”
* **机制：** 贝叶斯网络（BN），或一个更强大的“超级BN”（混合BN）。
* **过程：**
    1.  **输入（情境）：** 它接收“情境参数”（例如 `速度`, `尺度`, `温度`）。这些参数由LLM（例如 `LangChain` + `Gemini`）通过扫描文献中已知会影响该定律的因素来识别。
    2.  **输入（数据）：** 它将来自内循环的**似然得分**作为其目标变量。
    3.  **输出（认知）：** 它学习一个元模型（一个有向无环图 DAG），该模型描绘了这种关系：`P(适用性 | 情境_1, 情境_2, ...)`

#### 外循环的演进：从 BN 到 SCM

我们对外循环的选择是经过深思熟虑的，它代表了一条清晰的从“相关”到“因果”的升级路径：

1.  **标准贝叶斯网络 (Standard BN):**
    * **是什么：** 一个DAG，其中节点间的关系由**条件概率表 (CPTs)** 定义（例如 $P(Y | X=\text{true})$）。
    * **优点：** 强大的概率推理框架。
    * **缺点：** 难以处理连续变量（需要离散化，导致信息损失），并且CPT无法表达节点间复杂的**函数关系**。

2.  **超级贝叶斯网络 (Super BN / Hybrid BN):** (本框架的首选)
    * **是什么：** 这仍然是一个**保持了DAG结构**的贝叶斯网络。
    * **关键升级：** 我们用**强大的概率模型**（如线性回归、GAMs甚至高斯过程）来替换CPT。
    * **举例：** 节点关系不再是`P(Y|X)`的表格，而是由一个模型 $Y \sim \mathcal{N}(\mu=f(X), \sigma^2)$ 来定义。
    * **优点：** **完美地保留了BN的因果图结构**，同时能原生处理连续变量和复杂的非线性关系。它是一个更强大、更灵活的BN。

3.  **结构因果模型 (Structural Causal Model, SCM):**
    * **是什么：** 这是因果推断的“黄金标准”。它也是一个DAG，但节点间的关系由**确定性的函数赋值**和外生噪声项来定义（例如 $Y := f(X, \epsilon_Y)$）。
    * **与“超级BN”的关系：** 我们的“超级BN”本质上就是SCM的一个**概率化、可学习的近似**。
    * **核心优势：** 因为我们从一开始就保留了DAG结构并学习了函数$f(\cdot)$，所以从我们的“超级BN”**迁移到完整的SCM**（以进行“do-演算”或反事实推断）是**水到渠成**的。我们已经完成了最困难的部分——结构发现和函数拟合。这就是我们选择这条路径的战略考量。

#### 外循环的扩展性：应对高维情境的思路探讨

我们预见到一个挑战：当系统成熟时，它可能需要管理数百个`RuleClass`实例和数千个潜在的“情境参数”。外循环的DAG结构学习将面临“维度灾难”，成为一个NP-hard问题。

为了应对这种高维稀疏性（类似于混合专家网络, MoE），我们正在探索以下两种高级策略，这些策略是并行的思考方向，将随着项目的开发和扩展进行验证：

**策略A：多阶段的“过滤-精炼”混合策略 (用于BN结构学习)**

这是一种务实的、分而治之的工程方案，用于学习“超级BN”的结构：

1.  **步骤一：候选集筛选（特征选择）**
    * **数据驱动：** 运行一个计算高效的约束型因果发现算法（如MMPC），从海量（例如10000个）变量中，找到目标变量（如“规律适用性”）的马尔可夫毯（Markov Blanket）候选集 $C_{data}$。
    * **先验驱动：** 利用LLM从文献中提取所有与目标变量强相关的变量，形成先验候选集 $C_{prior}$。

2.  **步骤二：合并与精炼**
    * 取两个候选集的并集 $C_{union} = C_{data} \cup C_{prior}$。
    * 通过此步骤，我们将一个（10000个变量）的NP-hard问题，降维为一个（例如130个变量）的可解问题。

3.  **步骤三：精确的结构学习**
    * 在这个精炼后的子集上，我们现在可以运行计算成本更高、更精确的评分型（Score-based）结构学习算法（如GES或带禁忌列表的爬山算法）。
    * **LLM先验融合：** 在此阶段，LLM的先验（例如，文献中$i \to j$的概率$p_{ij}$）被用作评分函数的“软约束”（例如，作为贝叶斯评分的BDeu先验），以指导搜索偏向更符合科学直觉的图结构。

**策略B：基于先验的SCM正则化 (用于SCM函数学习)**

这是一种更“端到端”的算法方案，旨在与基于连续优化（梯度下降）的SCM学习算法（如NOTEARS）深度融合：

* **背景：** 此类算法通过学习一个权重矩阵 $W$ 来同时发现结构（$W_{ij} \neq 0$）和参数。但其损失函数是非凸的，极易陷入局部最优。
* **LLM先验的应用：**
    1.  **智能初始化：** 使用LLM先验来初始化 $W$ 矩阵。如果先验认为 $i \to j$ 很可能存在，则将 $W_{ij}$ 初始化为一个小的非零值，而不是0，从而将优化器“推送”到一个更有希望的损失区域。
    2.  **先验加权正则化：** 将LLM的先验知识**直接编译到损失函数**中，形成一个“先验加权的L1正则化项”：
        `Loss = L_{data} + \lambda \sum (\alpha_{ij} \cdot |W_{ij}|)`
        其中，惩罚系数 $\alpha_{ij}$ 是LLM先验的函数。如果LLM认为 $i \to j$ **极不可能**，我们就设置一个**极高的** $\alpha_{ij}$ 来惩罚这个非零权重，反之亦然。这是一种将符号知识熔铸到梯度优化中的优雅方式。

## 3. 动态引擎：一个学习*如何*学习的系统

Aetherium 不是静态的。它是一个旨在进化自身知识结构的智能体。

### 3.1. 为建模而主动学习（“好奇的科学家”）

* 系统主动地指导实验设计。
* **核心思想：** 它的目标**不是**优化某个物理属性（如“最高产率”，那是贝叶斯优化的工作），而是优化**信息增益的最大化**。
* 它会问：“如果我进行哪个实验，能最大程度地减少我*模型参数*（内循环）或*元模型*（外循环）的**不确定性**？” 它主动地寻找自己的“已知的未知”。

### 3.2. 动态结构演化（“适应的科学家”）

当一个规则在某个区域持续失效时，系统不会停止，它会试图理解*为什么*。

1.  **参数提升 (Parameter Promotion):** 系统可以假设某个*内部参数*（例如材料刚度 $k$）其本身就是一个“情境”。它动态地重写外循环BN，将 $k$ “提升”为一个因果父节点，从而建模*定律的适用性*是如何*随着其自身参数变得极端*而变化的。
2.  **规律切换 (Rule Switching):** 系统可以管理一个包含多个竞争性 `RuleClass` 的库（例如，牛顿力学 vs. 相对论力学）。外循环的任务可以演变为一个“混合专家”的门控，根据情境来决定当前*哪条规律*最适用。

### 3.3. 自主发现（“创造的科学家”）

这是该框架的终极目标：生成人类可读的新假设。

1.  **异常检测：** 系统首先识别出一个“失效区域”，在该区域中没有已知的规则适用。
2.  **经验建模：** 它建立一个“灰盒”模型（例如，高斯过程）来拟合该区域的数据，仅仅是为了从经验上把握它。
3.  **符号抽象：** 它将这个经验模型“喂”给一个**符号回归（Symbolic Regression）**引擎（例如 `PySR`）。
4.  **假设生成：** `PySR` 的输出是一个新的、简洁的符号公式（例如 $y = a \cdot \log(x)$）。然后，系统自动将这个公式包装成一个**新的 `RuleClass`**，整个学习循环重新开始，以测试这个由AI生成的新定律。

## 4. 提议的技术栈

这个框架是多个模块化工具的集合。

| 组件 | 技术 | 目的 |
| :--- | :--- | :--- |
| **项目与依赖** | `pyproject.toml` | 统一的项目管理 |
| **知识抽取** | `LangChain/langgraph`, `OpenAI` | LLM API调用, Prompt管理, 文本解析 |
| **内循环 (BU)** | `PyMC` / (未来优化可选)`NumPyro` | 概率编程, 贝叶斯推断 (MCMC/VI) |
| **外循环 (BN)** | `pgmpy` | 贝叶斯网络的定义、学习和推断 |
| **符号发现** | `PySR` | 符号回归 (发现新公式) |
| **关系发现(待定)** | `Problog` / `StarAI` (ILP) | (高级) 发现逻辑/关系规则 |
| **数据处理** | `Pandas`, `NumPy`, `SciPy` | 标准科学Python栈 |
| **工作流(待定)** | `Prefect` / `Dagster` | (推荐) 编排复杂的数据流水线 |
| **测试** | `pytest` | 确保代码质量和鲁棒性 |

## 5. 开发路线图

这是一个研究型项目。开发应遵循一个迭代式的4阶段计划。

1.  **阶段一：“行走骨架” (MVP)**
    * **目标：** 证明核心流水线（`RuleClass` -> 内循环 -> 外循环）在最简场景下能跑通。
    * **任务：**
        * 实现一个简单的 `RuleClass` (例如 $y=ax+b$)。
        * 使用 `PyMC` 实现一个最小化的 `InnerLoopEngine`。
        * 实现一个最小化的 `OuterLoopEngine` (桩函数)，它仅能接收似然得分。
        * 在硬编码的数据上运行。

2.  **阶段二：“被动科学家”**
    * **目标：** 构建一个能利用现有（离线）数据和文献的完整模型。
    * **任务：**
        * 将 `pgmpy` 完全集成到外循环中。
        * 集成 `LangChain`，使其能从文本文件中读取信息并构建BN结构。
        * 实现“批量学习”（预热 + 小批量）逻辑来处理静态数据集。

3.  **阶段三：“好奇的科学家”**
    * **目标：** 使系统变得数据高效。
    * **任务：**
        * 实现 `acquisition/` 模块。
        * 开发“不确定性采样”策略（基于内/外循环的不确定性）。
        * 创建一个模拟循环，让系统*建议*下一个要“采集”的数据点。

4.  **阶段四：“创造的科学家”**
    * **目标：** 实现自主进化和假设生成。
    * **任务：**
        * 实现“参数提升”和“规律切换”逻辑。
        * 将 `PySR` 集成到 `discovery/` 模块中。
        * 设计一个测试用例，让系统从一个简单定律的失败中“重新发现”一个更复杂的定律。
